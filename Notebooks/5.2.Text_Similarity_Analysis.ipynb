{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5.2. Text Similarity Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMT11OYwaC3M+NyKFxzcKB+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jcc329/Jessica_DATA606/blob/main/Notebooks/5.2.Text_Similarity_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data 606 Capstone\n",
        "## Notebook 5.2\n",
        "## Phase 2 Part 1: Topic Modeling\n",
        "Jessica Conroy\n",
        "\n",
        "<b> Goal: </b> \n",
        "This Notebook aims to perform topic modeling to identify key topics and differences in those topics among the pre covid and during covid time frames. \n",
        "1. LDA and NMF (non-negative matrix factorization) from game description, reviews, tags <br>\n",
        "<b>2. Text similarity analysis </b>"
      ],
      "metadata": {
        "id": "yA96G2XSkv5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim==3.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmLn8o-Xl11m",
        "outputId": "0d2152d8-5a67-4255-b59a-44b6eb00116d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim==3.8.0 in /usr/local/lib/python3.7/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.0) (1.21.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.0) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.0) (5.2.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.0) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==3.1.0a0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lJ6_yRWl1Em",
        "outputId": "24096c94-d668-48ea-b128-8194b0a821c8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans==3.1.0a0 in /usr/local/lib/python3.7/dist-packages (3.1.0a0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.7/dist-packages (from googletrans==3.1.0a0) (0.13.3)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2021.12.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.2.0)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2021.10.8)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUgGcA-RlKYI",
        "outputId": "c6f49d12-eda8-4c9d-bd72-148553c45cae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lrl9Ihsfx23Q",
        "outputId": "3cb3ae10-f393-4ad8-b4de-3ae0e1e2caeb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▏                           | 10 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 20 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 30 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 40 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 51 kB 17.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 61 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 71 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 79 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.63.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.11.1+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 44.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence_transformers) (3.10.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (4.11.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.49)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.11.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=8f1192d82b4d0551f1a50a11bdd4f51ad4c64dcc203ce097beeda93fca41dd98\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.0 sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mXDgvt6kfWD",
        "outputId": "855359c1-1456-4a87-a9b0-c81dfdf738a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.8.0\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import BertConfig, BertModel, BertTokenizer\n",
        "import seaborn as sns\n",
        "% matplotlib inline\n",
        "np.random.seed(42);\n",
        "\n",
        "#Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import textwrap\n",
        "\n",
        "import gensim\n",
        "print(gensim.__version__)\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import TfidfModel, LsiModel\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.parsing.preprocessing import preprocess_documents\n",
        "from io import TextIOWrapper\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "# print(stopwords.words('english'))\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GameData = pd.read_csv('./FinalSteamData.csv')"
      ],
      "metadata": {
        "id": "7XGopYAbIDdY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Similarity Analysis\n",
        "\n",
        "Based heavily on the work done in another text similarity project found here: https://github.com/Jcc329/Text_Summarization/blob/main/notebooks/Text_Similarity_Analysis_BERT_%26_Cos_Sim.ipynb\n",
        "\n",
        "https://seaborn.pydata.org/generated/seaborn.heatmap.html\n"
      ],
      "metadata": {
        "id": "tpC-2SYwxdNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "from sentence_transformers import SentenceTransformer\n",
        "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n"
      ],
      "metadata": {
        "id": "JFoQWLAextcS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GameData = pd.read_csv('./FinalGameData_postProcessing.csv')"
      ],
      "metadata": {
        "id": "T7emsAb05bNx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To compare across pre and during covid years, I will start by creating a matrix of siimilarities and differences based on game release year\n",
        "GameData['detailed_description.1'] = GameData['detailed_description.1'].astype(str)\n",
        "GameData['Top Reviews by Upvotes.1'] = GameData['Top Reviews by Upvotes.1'].astype(str)\n",
        "GameData['tags.1'] = GameData['tags.1'].astype(str)\n",
        "Agg_on_year = GameData.groupby(['Release Year'])[['detailed_description.1', 'Top Reviews by Upvotes.1', 'tags.1']].transform(lambda x: ' '.join(x))"
      ],
      "metadata": {
        "id": "lEy7NpgJlsiO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Descriptions\n",
        "description_embeddings = sbert_model.encode(Agg_on_year['detailed_description.1'])"
      ],
      "metadata": {
        "id": "bkAOWme_y3GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairwise_similarities=cosine_similarity(description_embeddings)\n",
        "pairwise_differences=euclidean_distances(description_embeddings)"
      ],
      "metadata": {
        "id": "LzieM5Lj0Kop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize similarities\n",
        "fig, ax = plt.subplots(figsize=(12,10))\n",
        "mask = np.zeros_like(pairwise_similarities)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "pairwise_similarities\n",
        "ax = sns.heatmap(\n",
        "    pairwise_similarities,\n",
        "    cmap=\"spectral\", mask=mask, annot=True, square=True).set(title='Similarities in Descriptions by year')\n",
        "ax.set_xticklabels(Agg_on_year['Release Year'])\n",
        "ax.set_yticklabels(Agg_on_year['Release Year'])\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=45,\n",
        "    horizontalalignment='right');\n",
        "ax.title()"
      ],
      "metadata": {
        "id": "lJ9h5oNg0ktW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Differences\n",
        "import seaborn as sns\n",
        "fig, ax = plt.subplots(figsize=(12,10))\n",
        "ax = sns.heatmap(\n",
        "    pairwise_differences,\n",
        "    cmap=\"spectral\", mask=mask, annot=True, square=True).set(title='Differences in Descriptions by year')\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=45,\n",
        "    horizontalalignment='right');"
      ],
      "metadata": {
        "id": "MFTws0e00mGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reviews\n",
        "Review_embeddings = sbert_model.encode(Agg_on_year['Top Reviews by Upvotes.1'])\n",
        "pairwise_similarities=cosine_similarity(Review_embeddings)\n",
        "pairwise_differences=euclidean_distances(Review_embeddings)"
      ],
      "metadata": {
        "id": "9mAioAZ32GGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize similarities\n",
        "fig, ax = plt.subplots(figsize=(12,10))\n",
        "mask = np.zeros_like(pairwise_similarities)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "pairwise_similarities\n",
        "ax = sns.heatmap(\n",
        "    pairwise_similarities,\n",
        "    cmap=\"magma\", mask=mask, annot=True, square=True).set(title='Similarities in Reviews by year')\n",
        "ax.set_xticklabels(Agg_on_year['Release Year'])\n",
        "ax.set_yticklabels(Agg_on_year['Release Year'])\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=45,\n",
        "    horizontalalignment='right');\n",
        "ax.title()"
      ],
      "metadata": {
        "id": "qtmPcD060-fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Differences\n",
        "import seaborn as sns\n",
        "fig, ax = plt.subplots(figsize=(12,10))\n",
        "ax = sns.heatmap(\n",
        "    pairwise_differences,\n",
        "    cmap=\"magma\", mask=mask, annot=True, square=True).set(title='Differences in Reviews by year')\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=45,\n",
        "    horizontalalignment='right');"
      ],
      "metadata": {
        "id": "uqXyhdTW2XHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tags\n",
        "Tag_embeddings = sbert_model.encode(Agg_on_year['tags.1'])\n",
        "pairwise_similarities=cosine_similarity(Tag_embeddings)\n",
        "pairwise_differences=euclidean_distances(Tag_embeddings)"
      ],
      "metadata": {
        "id": "cWieEvXO2anl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize similarities\n",
        "fig, ax = plt.subplots(figsize=(12,10))\n",
        "mask = np.zeros_like(pairwise_similarities)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "pairwise_similarities\n",
        "ax = sns.heatmap(\n",
        "    pairwise_similarities,\n",
        "    cmap=\"viridis\", mask=mask, annot=True, square=True).set(title='Similarities in Tags by year')\n",
        "ax.set_xticklabels(Agg_on_year['Release Year'])\n",
        "ax.set_yticklabels(Agg_on_year['Release Year'])\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=45,\n",
        "    horizontalalignment='right');\n",
        "ax.title()"
      ],
      "metadata": {
        "id": "iW_559774bae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Differences\n",
        "import seaborn as sns\n",
        "fig, ax = plt.subplots(figsize=(12,10))\n",
        "ax = sns.heatmap(\n",
        "    pairwise_differences,\n",
        "    cmap=\"viridis\", mask=mask, annot=True, square=True).set(title='Differences in Tags by year')\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=45,\n",
        "    horizontalalignment='right');"
      ],
      "metadata": {
        "id": "R9NfVF8U4cBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare pre-covid and during covid directly"
      ],
      "metadata": {
        "id": "yUwe91V3535A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preCOVID = GameData[GameData['Release Year'].isin([2018,2019])]\n",
        "COVID = GameData[GameData['Release Year'].isin([2021,2022])]"
      ],
      "metadata": {
        "id": "hkWtnfKn521z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preCOVID_descriptions = preCOVID['detailed_description.1'].apply(lambda x: ' '.join(x))\n",
        "COVID_descriptions = COVID['detailed_description.1'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "corpus = [preCOVID_descriptions, COVID_descriptions]\n",
        "description_embeddings = sbert_model.encode(corpus)"
      ],
      "metadata": {
        "id": "_fb8cMfG52-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairwise_similarities=cosine_similarity(description_embeddings)\n",
        "pairwise_differences=euclidean_distances(description_embeddings)\n",
        "\n",
        "print('Cosine Similarity: ' + str(pairwise_similarities[0][1]))\n",
        "print('Euclidean Distance: ' + str(pairwise_differences[0][1]))"
      ],
      "metadata": {
        "id": "WRRcJ2ds6rRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Zo1_9pls921Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
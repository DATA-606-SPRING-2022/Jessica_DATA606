{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5. Topic Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN1IPy/0lHarHNiujVNXr1c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jcc329/Jessica_DATA606/blob/main/Notebooks/5.Topic_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data 606 Capstone\n",
        "## Notebook 5\n",
        "## Phase 2 Part 1: Topic Modeling\n",
        "Jessica Conroy\n",
        "\n",
        "<b> Goal: </b> \n",
        "This Notebook aims to perform topic modeling to identify key topics and differences in those topics among the pre covid and during covid time frames. \n",
        "1. LDA and NMF (non-negative matrix factorization) from game description, reviews, tags\n",
        "2. Text similarity analysis"
      ],
      "metadata": {
        "id": "_z1j8bTzcRPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim==3.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRc4bBXsdAVA",
        "outputId": "e8a58ce4-b21f-482b-afac-521aef10161a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim==3.8.0 in /usr/local/lib/python3.7/dist-packages (3.8.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.0) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.0) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.0) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.0) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install googletrans==3.1.0a0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "fA7J_GrKgd-P",
        "outputId": "30bf0a12-3b87-452c-d46f-c09ae4ec0e3d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.7/dist-packages (from googletrans==3.1.0a0) (0.13.3)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2021.10.8)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2021.12.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.2.0)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16367 sha256=a8da55423c1f21e6773f52664a80dcf75a8505d2d06523d74706375d095f3eb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/be/fe/93a6a40ffe386e16089e44dad9018ebab9dc4cb9eb7eab65ae\n",
            "Successfully built googletrans\n",
            "Installing collected packages: googletrans\n",
            "  Attempting uninstall: googletrans\n",
            "    Found existing installation: googletrans 3.0.0\n",
            "    Uninstalling googletrans-3.0.0:\n",
            "      Successfully uninstalled googletrans-3.0.0\n",
            "Successfully installed googletrans-3.1.0a0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "googletrans"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T2gI5kSF7fJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ca7e07-808c-45d4-9787-2c0e6a6dd6dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.8.0\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import textwrap\n",
        "\n",
        "import gensim\n",
        "print(gensim.__version__)\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import TfidfModel, LsiModel\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.parsing.preprocessing import preprocess_documents\n",
        "from io import TextIOWrapper\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "# print(stopwords.words('english'))\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Data\n",
        "# GameData = pd.read_csv('./FinalSteamData.csv')\n",
        "GameData = pd.read_csv('./FinalGameData_postProcessing.csv')\n",
        "# GameData.head()"
      ],
      "metadata": {
        "id": "I-6HMlzecNkX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform some pre-requisite text processing"
      ],
      "metadata": {
        "id": "41IbX4B3l9fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove digits from tags. \n",
        "\n",
        "def removedigit(s):\n",
        "    try:\n",
        "        s = re.sub(\"\\d+\", \"\", s)\n",
        "    except: \n",
        "        s\n",
        "    return s\n",
        "GameData['tags.1'] = GameData['tags.1'].apply(removedigit)\n",
        "GameData['tags.1']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GUBwJt0dN8X",
        "outputId": "cb4de834-77bd-4e71-a08f-83112a8422a5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        action  casual  arcade  shoot em up  d  colorf...\n",
              "1                                                      NaN\n",
              "2                                                      NaN\n",
              "3        bullet hell  coop  shoot em up  replay value  ...\n",
              "4        action  shooter  action rpg  shoot em up  rpg ...\n",
              "                               ...                        \n",
              "14947    adventure  indie  point  click  puzzle  short ...\n",
              "14948                                                  NaN\n",
              "14949                                   adventure  casual \n",
              "14950                                                  NaN\n",
              "14951                                                  NaN\n",
              "Name: tags.1, Length: 14952, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatize the text (Lemmatisation in linguistics is the process of grouping together the inflected forms of a word so they can be analysed as a single item)\n",
        "# Topic modeling functions are informed and guided by another project I worked on https://github.com/Jcc329/Text_Summarization/blob/main/notebooks/Topic_Modeling_YunpengLi.ipynb\n",
        "# used methods for lemmatizing found here https://www.geeksforgeeks.org/python-lemmatization-approaches-with-examples/\n",
        "\n",
        "def pos_tagger(nltk_tag):\n",
        "    if nltk_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif nltk_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif nltk_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif nltk_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:         \n",
        "        return None\n",
        "def nltk_lemmatize(s):\n",
        "    pos_tagged = nltk.pos_tag(nltk.word_tokenize(str(s))) \n",
        "    wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
        "    lemmatized_sentence = []\n",
        "    for word, tag in wordnet_tagged:\n",
        "        if tag is None:\n",
        "            # if there is no available tag, append the token as is\n",
        "            lemmatized_sentence.append(word)\n",
        "        else:       \n",
        "            # else use the tag to lemmatize the token\n",
        "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
        "    lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
        "    return lemmatized_sentence\n",
        "GameData['tags.1'] = GameData['tags.1'].apply(nltk_lemmatize)\n",
        "# GameData['tags.1']\n",
        "GameData['detailed_description.1'] = GameData['detailed_description.1'].apply(nltk_lemmatize)\n",
        "# GameData['detailed_description.1']\n",
        "GameData['Top Reviews by Upvotes.1'] = GameData['Top Reviews by Upvotes.1'].apply(nltk_lemmatize)\n",
        "# GameData['Top Reviews by Upvotes.1']"
      ],
      "metadata": {
        "id": "VM7JA85fdWGo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove additional stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "stop_words = stop_words.update([\"game\",'games', \"player\", 'play'])\n",
        "\n",
        "def removestopwords(s):\n",
        "    #Remove stop words and sent to lowercase\n",
        "    try:\n",
        "        s = \" \".join([word.lower() for word in str(s).split() if word.lower() not in stop_words])\n",
        "    except:\n",
        "        s\n",
        "    return s\n",
        "\n",
        "GameData['tags.1'] = GameData['tags.1'].apply(removestopwords)\n",
        "# GameData['tags.1']\n",
        "GameData['detailed_description.1'] = GameData['detailed_description.1'].apply(removestopwords)\n",
        "# GameData['detailed_description.1']\n",
        "GameData['Top Reviews by Upvotes.1'] = GameData['Top Reviews by Upvotes.1'].apply(removestopwords)\n",
        "# GameData['Top Reviews by Upvotes.1']"
      ],
      "metadata": {
        "id": "smIupFKEjQEf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out non english text\n",
        "#https://pypi.org/project/googletrans/\n",
        "#https://stackoverflow.com/questions/57282711/google-translate-library-is-printing-googletrans-models-translated-at-0x1eaf9bf\n",
        "\n",
        "def taglanguage(df,col):\n",
        "    lang_tag = []\n",
        "    for s in df[col]:\n",
        "        translator = Translator()\n",
        "        result = translator.detect(s[0:100])\n",
        "        lang_tag.append(result.lang)\n",
        "    # print(lang.detect_language())\n",
        "    return lang_tag\n",
        "\n",
        "GameData['tags.Lang'] = taglanguage(GameData, 'tags.1')\n",
        "# GameData['tags.1']\n",
        "GameData['detailed_description.Lang'] =  taglanguage(GameData, 'detailed_description.1')\n",
        "# GameData['detailed_description.1']\n",
        "GameData['Top Reviews by Upvotes.Lang'] =  taglanguage(GameData, 'Top Reviews by Upvotes.1')\n",
        "# GameData['detailed_description.Lang']\n",
        "GameData.to_csv('./FinalGameData_postProcessing.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSqOcnJUgD5V",
        "outputId": "0812ae86-d4c6-48c0-9f6d-537593c19800"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        en\n",
              "1        en\n",
              "2        en\n",
              "3        en\n",
              "4        en\n",
              "         ..\n",
              "14947    en\n",
              "14948    en\n",
              "14949    en\n",
              "14950    en\n",
              "14951    en\n",
              "Name: detailed_description.Lang, Length: 14952, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('FinalGameData_postProcessing.csv')"
      ],
      "metadata": {
        "id": "C8cZGsNQ9u_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GameData[GameData['detailed_description.Lang']!='en']\n",
        "GameData[GameData['detailed_description.Lang'].astype(str).str.contains('en')]['detailed_description.1'].values\n",
        "#Nans were interpretted as [ht, zh-CN]\t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd6YLVzdND5y",
        "outputId": "56c5e047-6c74-4a75-abc0-f04ced819b64"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['universe implodes interstellar nomad race get back home galaxy star violently push toward home threaten destroy nomad get catch path survive round relentless onslaught secure survival nomad game play several round round number nomad try make back home must defend swing intergalactic sword around fire projectile reflect galaxy star back origin key feature campaign span 60 mission mission increase duration difficulty random game experience random encounter implode verse simplistic control game fully play mouse huge sword attach nomad another one home sword point mouse cursor lmb reflect hazard adjacent sword rmb shoot projectile every sword toward position mouse cursor hazard collide sword destroy reflect hazard numerous type hazard require different approach hazard go home directly attack nomad multiple vector usually either tile bullet hell mechanic make round however boss round might mix match mechanic even add new one challenge you',\n",
              "       'pilot rc drone target course rc target dronez castlepunk beat best time navigate target gate multiple course 2 environment medieval castle cyberpunk setting purchase rc target dronez dlc add game collection continue play get rotate arcade floorthis game currently available play free neighborhood arcade',\n",
              "       'pilot rc drone target course rc target dronez castlepunk beat best time navigate target gate multiple course 2 environment medieval castle cyberpunk setting purchase rc target dronez dlc add game collection continue play get rotate arcade floorthis game currently available play free neighborhood arcade',\n",
              "       ...,\n",
              "       'kingdom ’ s future rest light three beacon light time shadow cast lightiris escape tower still need help explore kingdom stonebriar solve mystery shadow prowl street fun adventure game enter magical world colorful painting meet host fantastic character help quest draw dark flight someone power imagination unravel mystery three beacon save future queen bring hope back peoplegorgeous scenesfantastic puzzle minigameshelp iris light beacon',\n",
              "       'gain item accessory inspire vtuber group quotaogiri high schoolquot ・themed recovery item x 50 per vtuber ・themed mask x 3 per vtuber ・themed accessory x 3 per vtuber ・special quotxquot cube member quotaogiri high schoolquot in order receive vtubers special quotxquot cube need rescue respective character first',\n",
              "       'open cup medic setthe open cup set equipment include gear medic tactical shotgun sidewinder venom item allow game official esports tournament well rank match well suit pvp battlesthe uniform impressive defense headshot well explosion flash grenade also increase reload speed weapon change speedthe helmet help restore health quicker vest reduce damage 10 point per hit glove increase accuracy tournament boot help use sprint effectively avoid claymoresby equip 4 item set armor increase 15 additional pointsthe sidewinder venom magfed tactical pumpaction shotgun system upgraded version mossberg 590 modification shortcoming since shotgun parameter high performance weapon come equip three unique attachment venom wraptor forend handle trijicon rmr adjustable lead collimatorthe shotgun high damage good range rate fire well impressive magazine disadvantage be doesn ’ t high accuracy'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions for preparing the text data for the LDA/NMF model application and doing coherence testing"
      ],
      "metadata": {
        "id": "tcYBnatwmTQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split text into corpuses showing array of values\n",
        "#Create Pre and During Covid data sets to use later:\n",
        "preCOVID = GameData[GameData['Release Year'].isin([2018,2019])]\n",
        "COVID = GameData[GameData['Release Year'].isin([2021,2022])]\n",
        "\n",
        "# All Data\n",
        "Descriptions_all = GameData[GameData['detailed_description.Lang'].astype(str).str.contains('en')]['detailed_description.1'].values\n",
        "Reviews_all = GameData[GameData['Top Reviews by Upvotes.Lang'].astype(str).str.contains('en')]['Top Reviews by Upvotes.1'].values\n",
        "Tags_all = GameData[GameData['tags.Lang'].astype(str).str.contains('en')]['tags.1'].values\n",
        "\n",
        "# preCOVID Data\n",
        "Descriptions_preCOVID = preCOVID[preCOVID['detailed_description.Lang'].astype(str).str.contains('en')]['detailed_description.1'].values\n",
        "Reviews_preCOVID = preCOVID[preCOVID['Top Reviews by Upvotes.Lang'].astype(str).str.contains('en')]['Top Reviews by Upvotes.1'].values\n",
        "Tags_preCOVID = preCOVID[preCOVID['tags.Lang'].astype(str).str.contains('en')]['tags.1'].values\n",
        "\n",
        "# duringCOVID Data\n",
        "Descriptions_COVID = COVID[COVID['detailed_description.Lang'].astype(str).str.contains('en')]['detailed_description.1'].values\n",
        "Reviews_COVID = COVID[COVID['Top Reviews by Upvotes.Lang'].astype(str).str.contains('en')]['Top Reviews by Upvotes.1'].values\n",
        "Tags_COVID = COVID[COVID['tags.Lang'].astype(str).str.contains('en')]['tags.1'].values"
      ],
      "metadata": {
        "id": "4Z_pzDZwmeAu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create dictionary, bag of words, and tokenized text: https://github.com/Jcc329/Text_Summarization/blob/main/notebooks/Topic_Modeling_YunpengLi.ipynb\n",
        "# https://radimrehurek.com/gensim/parsing/preprocessing.html\n",
        "def build_dictionary_preprocess_corpus(text_corpus):\n",
        "  \n",
        "  # Preprocess documents \n",
        "  tokenized_texts = preprocess_documents(text_corpus)\n",
        "  \n",
        "  # Create a dictionary\n",
        "  dictionary = Dictionary(tokenized_texts)\n",
        "  \n",
        "  # Create a list of lists of bow for documents\n",
        "  bow_corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
        "\n",
        "  return dictionary, bow_corpus, tokenized_texts"
      ],
      "metadata": {
        "id": "rn2XsctpjLyn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for calculating coherence score: https://github.com/Jcc329/Text_Summarization/blob/main/notebooks/Topic_Modeling_YunpengLi.ipynb\n",
        "# coherence_type can be 'u_mass' or 'c_v'\n",
        "# algorithm can be 'LSI' or 'LDA'\n",
        "def compute_coherence_score(tokenized_texts, bow_corpus, dictionary, num_topics, coherence_type, algorithm):\n",
        "  if algorithm == 'LSI':\n",
        "    model = LsiModel(corpus = bow_corpus, num_topics = num_topics, id2word = dictionary)\n",
        "  else: # algorithm == 'LDA'\n",
        "    model = LdaModel(corpus = bow_corpus, num_topics = num_topics, id2word = dictionary, passes = 2)\n",
        "\n",
        "  coherence = CoherenceModel(model=model,\n",
        "                              corpus=bow_corpus,\n",
        "                              texts=tokenized_texts,\n",
        "                              dictionary=dictionary,\n",
        "                              coherence=coherence_type)\n",
        "  return coherence.get_coherence()"
      ],
      "metadata": {
        "id": "-DC-vR3WmcW2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_coherence_scores(min_topics, max_topics, tokenized_texts, bow_corpus, dictionary, algorithm, coherence_type='u_mass'):\n",
        "  \n",
        "  coherence_scores=[]\n",
        "  min_score=0\n",
        "  max_score=0\n",
        "\n",
        "  best_num_topics=1\n",
        "\n",
        "  for k in range(min_topics, max_topics):\n",
        "    score = compute_coherence_score(tokenized_texts, bow_corpus, dictionary, k, coherence_type, algorithm)\n",
        "    coherence_scores.append(score)\n",
        "\n",
        "    if coherence_type == 'u_mass':\n",
        "      if score < min_score :\n",
        "        min_score = score\n",
        "        best_num_topics = k\n",
        "    else: # coherence_type == 'c_v'\n",
        "      if score > max_score:\n",
        "        max_score = score\n",
        "        best_num_topics= k\n",
        "\n",
        "\n",
        "  return coherence_scores, best_num_topics"
      ],
      "metadata": {
        "id": "AQaBy52coQnI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for plotting coherence score\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.style as style\n",
        "#%matplotlib inline\n",
        "\n",
        "def plot_coherence_scores(min_topics, max_topics, coherence_scores, coherence_type, algorithm, legend=''):\n",
        "  style.use('fivethirtyeight')\n",
        "\n",
        "  x = [int(i) for i in range(min_topics, max_topics)]\n",
        "\n",
        "  plt.figure(figsize=(10,8))\n",
        "  plt.plot(x, coherence_scores)\n",
        "  plt.xlabel('Number of topics')\n",
        "  plt.ylabel('Coherence Value')\n",
        "  plt.title(legend + ' ' + algorithm + ' Coherence Scores by number of Topics (' + coherence_type + ')')"
      ],
      "metadata": {
        "id": "EoUCVDqnoqAd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to print topics\n",
        "def print_topics(dictionary, bow_corpus, num_topics, algorithm, num_words=10, friendly_print=True):\n",
        "  \n",
        "  if algorithm == 'LSI':\n",
        "    model = LsiModel(corpus=bow_corpus, num_topics=num_topics, id2word=dictionary)\n",
        "  else: # algorithm == 'LDA'\n",
        "    model = LdaModel(corpus=bow_corpus, num_topics=num_topics, id2word=dictionary, passes=2)\n",
        "\n",
        "  if friendly_print:\n",
        "    # Extract terms from results returned by show_topic()\n",
        "    for topic_number in range(0, num_topics):\n",
        "      terms = []\n",
        "      for term, wt in model.show_topic(topic_number, num_words):\n",
        "        terms.append(term)\n",
        "    \n",
        "      print('Topic ' + str(topic_number) + ':', terms)\n",
        "\n",
        "  else:\n",
        "    topics = model.print_topics(num_topics, num_words)\n",
        "    for topic in topics:\n",
        "      print(topic)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "aXExpW-irMF-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for NMF Modeling"
      ],
      "metadata": {
        "id": "LqKGj-ePGG8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "nkXOVbEgrPXt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_NMF_topics(tokenized_texts, max_df=0.95, min_df=1, number_topics=20, number_words_per_topic=10):\n",
        "  \n",
        "  text_list=[]\n",
        "\n",
        "  for token_array in tokenized_texts:\n",
        "    text_list.append(\" \".join(token_array))  # concat tokens for each document to make compatible format for vectorizer.fit_transform()\n",
        "\n",
        "  vectorizer = TfidfVectorizer(max_df=max_df, min_df=min_df, stop_words='english')\n",
        "  X = vectorizer.fit_transform(text_list)\n",
        "\n",
        "  idx_to_word = np.array(vectorizer.get_feature_names())\n",
        "\n",
        "  # apply NMF\n",
        "  nmf = NMF(n_components=number_topics, solver=\"mu\")\n",
        "  W = nmf.fit_transform(X)  # document_topics\n",
        "  H = nmf.components_       # topic_terms\n",
        "\n",
        "  for i, topic in enumerate(H):\n",
        "    print(\"Topic {}: {}\".format(i + 1, \",\".join([str(x) for x in idx_to_word [topic.argsort()[-number_words_per_topic:]]])))"
      ],
      "metadata": {
        "id": "V0vxfmsbGAk_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run the models"
      ],
      "metadata": {
        "id": "TrCEFqy1ramt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#All Data\n",
        "\n",
        "## Descriptions"
      ],
      "metadata": {
        "id": "9P_LBaFXu8Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We are using u_mass over c_v to calculate coherence because u_mass measures relationships with preceding and subsequent words and tends to perform better when compared with other coherence metrics (https://github.com/dice-group/Palmetto/issues/12)\n",
        "dictionary, bow_corpus, tokenized_texts = build_dictionary_preprocess_corpus(Descriptions_all)\n",
        "min_topics, max_topics = 5, 100\n",
        "coherence_scores_u_mass_lda, best_num_topics_u_mass_lda = generate_coherence_scores(min_topics, max_topics, tokenized_texts, bow_corpus, dictionary, algorithm='LDA', coherence_type='u_mass')\n",
        "plot_coherence_scores(min_topics, max_topics, coherence_scores_u_mass_lda, coherence_type='u_mass', algorithm='LDA')"
      ],
      "metadata": {
        "id": "Q9C_tu4FueC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The best number of Description topics found by u-mass coherence score:', best_num_topics_u_mass_lda)"
      ],
      "metadata": {
        "id": "K3wfyym8zG8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = print_topics(dictionary, bow_corpus, best_num_topics_u_mass_lda, algorithm='LDA', num_words=15, friendly_print=True)"
      ],
      "metadata": {
        "id": "Nm09Nvh_4gna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_NMF_topics(tokenized_texts)"
      ],
      "metadata": {
        "id": "UjsZCaL3F8ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reviews"
      ],
      "metadata": {
        "id": "YipxkcVgvN_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary, bow_corpus, tokenized_texts = build_dictionary_preprocess_corpus(Reviews_all)\n",
        "min_topics, max_topics = 5, 100\n",
        "coherence_scores_u_mass_lda, best_num_topics_u_mass_lda = generate_coherence_scores(min_topics, max_topics, tokenized_texts, bow_corpus, dictionary, algorithm='LDA', coherence_type='u_mass')\n",
        "plot_coherence_scores(min_topics, max_topics, coherence_scores_u_mass_lda, coherence_type='u_mass', algorithm='LDA')"
      ],
      "metadata": {
        "id": "f0o9hqiIvQJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The best number of Review topics found by u-mass coherence score:', best_num_topics_u_mass_lda)"
      ],
      "metadata": {
        "id": "9gVSjOYWvS5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = print_topics(dictionary, bow_corpus, best_num_topics_u_mass_lda, algorithm='LDA', num_words=15, friendly_print=True)"
      ],
      "metadata": {
        "id": "Tb6MJTSYvaM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_NMF_topics(tokenized_texts)"
      ],
      "metadata": {
        "id": "FefXoHBoGOhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tags"
      ],
      "metadata": {
        "id": "ewiaxWGYveh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary, bow_corpus, tokenized_texts = build_dictionary_preprocess_corpus(Tags_all)\n",
        "min_topics, max_topics = 5, 100\n",
        "coherence_scores_u_mass_lda, best_num_topics_u_mass_lda = generate_coherence_scores(min_topics, max_topics, tokenized_texts, bow_corpus, dictionary, algorithm='LDA', coherence_type='u_mass')\n",
        "plot_coherence_scores(min_topics, max_topics, coherence_scores_u_mass_lda, coherence_type='u_mass', algorithm='LDA')"
      ],
      "metadata": {
        "id": "-Pa0FsIdvc4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The best number of Review topics found by u-mass coherence score:', best_num_topics_u_mass_lda)"
      ],
      "metadata": {
        "id": "hLC8PPSYvktV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = print_topics(dictionary, bow_corpus, best_num_topics_u_mass_lda, algorithm='LDA', num_words=15, friendly_print=True)"
      ],
      "metadata": {
        "id": "h1frOPzTvmIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_NMF_topics(tokenized_texts)"
      ],
      "metadata": {
        "id": "aziGEE_JGPoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pre-Covid\n",
        "## Descriptions"
      ],
      "metadata": {
        "id": "NlRLApqHu_mL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary, bow_corpus, tokenized_texts = build_dictionary_preprocess_corpus(Descriptions_preCOVID)\n",
        "min_topics, max_topics = 5, 100\n",
        "coherence_scores_u_mass_lda, best_num_topics_u_mass_lda = generate_coherence_scores(min_topics, max_topics, tokenized_texts, bow_corpus, dictionary, algorithm='LDA', coherence_type='u_mass')\n",
        "plot_coherence_scores(min_topics, max_topics, coherence_scores_u_mass_lda, coherence_type='u_mass', algorithm='LDA')"
      ],
      "metadata": {
        "id": "0WEcyF4ztBm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The best number of Review topics found by u-mass coherence score:', best_num_topics_u_mass_lda)"
      ],
      "metadata": {
        "id": "sNUUhCdewAYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = print_topics(dictionary, bow_corpus, best_num_topics_u_mass_lda, algorithm='LDA', num_words=15, friendly_print=True)"
      ],
      "metadata": {
        "id": "Yv2Xy01ywCbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_NMF_topics(tokenized_texts)"
      ],
      "metadata": {
        "id": "BKjYQ891GRBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reviews"
      ],
      "metadata": {
        "id": "J9lEy04WwF8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary, bow_corpus, tokenized_texts = build_dictionary_preprocess_corpus(Reviews_preCOVID)\n",
        "min_topics, max_topics = 5, 100\n",
        "coherence_scores_u_mass_lda, best_num_topics_u_mass_lda = generate_coherence_scores(min_topics, max_topics, tokenized_texts, bow_corpus, dictionary, algorithm='LDA', coherence_type='u_mass')\n",
        "plot_coherence_scores(min_topics, max_topics, coherence_scores_u_mass_lda, coherence_type='u_mass', algorithm='LDA')"
      ],
      "metadata": {
        "id": "zO5GDQZzwDLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The best number of Review topics found by u-mass coherence score:', best_num_topics_u_mass_lda)"
      ],
      "metadata": {
        "id": "X463s-_DwLAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = print_topics(dictionary, bow_corpus, best_num_topics_u_mass_lda, algorithm='LDA', num_words=15, friendly_print=True)"
      ],
      "metadata": {
        "id": "REV542uVwNUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_NMF_topics(tokenized_texts)"
      ],
      "metadata": {
        "id": "l7r9R0_PGR77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tags"
      ],
      "metadata": {
        "id": "40Zfw_PIwObh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary, bow_corpus, tokenized_texts = build_dictionary_preprocess_corpus(Tags_preCOVID)\n",
        "min_topics, max_topics = 5, 100\n",
        "coherence_scores_u_mass_lda, best_num_topics_u_mass_lda = generate_coherence_scores(min_topics, max_topics, tokenized_texts, bow_corpus, dictionary, algorithm='LDA', coherence_type='u_mass')\n",
        "plot_coherence_scores(min_topics, max_topics, coherence_scores_u_mass_lda, coherence_type='u_mass', algorithm='LDA')"
      ],
      "metadata": {
        "id": "XQV7IytfwQbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The best number of Review topics found by u-mass coherence score:', best_num_topics_u_mass_lda)"
      ],
      "metadata": {
        "id": "PzoML5nSwXHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = print_topics(dictionary, bow_corpus, best_num_topics_u_mass_lda, algorithm='LDA', num_words=15, friendly_print=True)"
      ],
      "metadata": {
        "id": "BnkLuAG_wWRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_NMF_topics(tokenized_texts)"
      ],
      "metadata": {
        "id": "MinLpDtiGS4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Covid Data\n",
        "## Description"
      ],
      "metadata": {
        "id": "7GCUZRvuwa6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary, bow_corpus, tokenized_texts = build_dictionary_preprocess_corpus(Descriptions_COVID)\n",
        "min_topics, max_topics = 5, 100\n",
        "coherence_scores_u_mass_lda, best_num_topics_u_mass_lda = generate_coherence_scores(min_topics, max_topics, tokenized_texts, bow_corpus, dictionary, algorithm='LDA', coherence_type='u_mass')\n",
        "plot_coherence_scores(min_topics, max_topics, coherence_scores_u_mass_lda, coherence_type='u_mass', algorithm='LDA')"
      ],
      "metadata": {
        "id": "EXJ1mB9YweRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The best number of Review topics found by u-mass coherence score:', best_num_topics_u_mass_lda)"
      ],
      "metadata": {
        "id": "KZUzYD2BweMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = print_topics(dictionary, bow_corpus, best_num_topics_u_mass_lda, algorithm='LDA', num_words=15, friendly_print=True)"
      ],
      "metadata": {
        "id": "pGSUAETlweEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_NMF_topics(tokenized_texts)"
      ],
      "metadata": {
        "id": "h59soSL3GTwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reviews"
      ],
      "metadata": {
        "id": "ASPnbh1IwkGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary, bow_corpus, tokenized_texts = build_dictionary_preprocess_corpus(Reviews_COVID)\n",
        "min_topics, max_topics = 5, 100\n",
        "coherence_scores_u_mass_lda, best_num_topics_u_mass_lda = generate_coherence_scores(min_topics, max_topics, tokenized_texts, bow_corpus, dictionary, algorithm='LDA', coherence_type='u_mass')\n",
        "plot_coherence_scores(min_topics, max_topics, coherence_scores_u_mass_lda, coherence_type='u_mass', algorithm='LDA')"
      ],
      "metadata": {
        "id": "-mWkl8DWwjRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The best number of Review topics found by u-mass coherence score:', best_num_topics_u_mass_lda)"
      ],
      "metadata": {
        "id": "-y2nn7ZHwmzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = print_topics(dictionary, bow_corpus, best_num_topics_u_mass_lda, algorithm='LDA', num_words=15, friendly_print=True)"
      ],
      "metadata": {
        "id": "M1W9xvLZwoZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_NMF_topics(tokenized_texts)"
      ],
      "metadata": {
        "id": "-tmXV0JwGUhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tags"
      ],
      "metadata": {
        "id": "L29_8Hn2wrLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary, bow_corpus, tokenized_texts = build_dictionary_preprocess_corpus(Tags_COVID)\n",
        "min_topics, max_topics = 5, 100\n",
        "coherence_scores_u_mass_lda, best_num_topics_u_mass_lda = generate_coherence_scores(min_topics, max_topics, tokenized_texts, bow_corpus, dictionary, algorithm='LDA', coherence_type='u_mass')\n",
        "plot_coherence_scores(min_topics, max_topics, coherence_scores_u_mass_lda, coherence_type='u_mass', algorithm='LDA')"
      ],
      "metadata": {
        "id": "rYGybJqawtV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The best number of Review topics found by u-mass coherence score:', best_num_topics_u_mass_lda)"
      ],
      "metadata": {
        "id": "am6amEaOw4iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = print_topics(dictionary, bow_corpus, best_num_topics_u_mass_lda, algorithm='LDA', num_words=15, friendly_print=True)"
      ],
      "metadata": {
        "id": "QZb4bnMVv7tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_NMF_topics(tokenized_texts)"
      ],
      "metadata": {
        "id": "vx7tB14QGVgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## LDAvis "
      ],
      "metadata": {
        "id": "gLwSZOLuFXls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis==2.1.2"
      ],
      "metadata": {
        "id": "oD9-Vx0iFXg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.gensim\n",
        "\n",
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()"
      ],
      "metadata": {
        "id": "LoDB6ciZFXc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vis = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary)\n",
        "vis"
      ],
      "metadata": {
        "id": "2NxSnmxHFfIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# See Notebook 5.2 for text similarity analysis"
      ],
      "metadata": {
        "id": "sr2J1w2Fw7jE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4TuodAxcIsam"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}